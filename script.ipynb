{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3NuCIiT-nUPE",
        "tPb5buByn0rr",
        "wRbZBeiPpGg9",
        "cAaTRTufp2PL",
        "RGjtx0iyrJiJ",
        "5dMprukvsb2L",
        "Ffi6OwUtvMZb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "3NuCIiT-nUPE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0ft9h7EnFxH"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install lime\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Set the device to GPU if available, otherwise CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First model classification"
      ],
      "metadata": {
        "id": "tPb5buByn0rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "data = pd.read_csv(\"data.csv\", ignore_index=True)  # Load the CSV file and reset the index\n",
        "\n",
        "# Configure the classification model\n",
        "MODEL = \"tomh/toxigen_hatebert\"  # Specify the model you want to use (e.g., a pre-trained hate speech model)\n",
        "clf = pipeline(\"text-classification\", model=MODEL, tokenizer=\"bert-base-cased\", truncation=True)  # Create the text classification pipeline with the model and BERT tokenizer\n",
        "\n",
        "# Start the prediction on the dataset\n",
        "data.reset_index(inplace=True)  # Reset the DataFrame index to avoid conflicts with existing indices\n",
        "list_result = []  # List to store the prediction results\n",
        "for i in range(len(data)):  # Iterate over all the rows in the dataset\n",
        "    print(i)  # Print the index for monitoring\n",
        "    list_result.append(clf(data.loc[i, \"text\"]))  # Get the prediction for each row in the dataset\n",
        "\n",
        "# Extract the prediction labels\n",
        "risultati = []  # List to store the predicted labels\n",
        "for i in range(len(list_result)):  # Iterate over the prediction results\n",
        "    risultati.append(list_result[i][0][\"label\"])  # Append each prediction label to the list\n",
        "\n",
        "# Add the predicted labels column to the DataFrame\n",
        "data[\"prediction_label_iniziale\"] = risultati  # Insert the predicted labels into the 'prediction_label_iniziale' column\n",
        "\n",
        "# Replace the predicted labels \"LABEL_0\" and \"LABEL_1\" to match the format of the original labels in the dataset\n",
        "# This is necessary to ensure that the predicted labels align with the true labels for calculating accuracy\n",
        "data.prediction_label_iniziale.replace(\"LABEL_0\", 2, inplace=True)  # Replace 'LABEL_0' with 2 (hate speech)\n",
        "data.prediction_label_iniziale.replace(\"LABEL_1\", 0, inplace=True)  # Replace 'LABEL_1' with 0 (non-hate speech)\n",
        "\n",
        "# Convert the predicted and true labels to integers for accuracy calculation\n",
        "data[\"prediction_label_iniziale\"] = data[\"prediction_label_iniziale\"].astype(int)\n",
        "data[\"hatespeech\"] = data[\"hatespeech\"].astype(int)  # Ensure the 'hatespeech' column is an integer for comparison\n",
        "\n",
        "# Calculate the accuracy of the model by comparing the predicted labels with the true labels\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(data['hatespeech'], data[\"prediction_label_iniziale\"])\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "A0khekX2n3sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIME"
      ],
      "metadata": {
        "id": "wRbZBeiPpGg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import lime  # Library for interpretable machine learning\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from lime.lime_text import LimeTextExplainer  # Lime explainer for text data\n",
        "\n",
        "class_names = [\"LABEL_0\", \"LABEL_1\"]  # Define class names\n",
        "\n",
        "# Load model and tokenizer from Hugging Face\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")  # Tokenizer for BERT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"tomh/toxigen_hatebert\")  # Load pre-trained model for hate speech classification\n",
        "model.to(device)  # Move the model to the GPU or CPU depending on the device\n",
        "\n",
        "# Define the predictor function that takes text inputs and returns prediction probabilities\n",
        "def predictor(texts):\n",
        "    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True).to(device))  # Tokenize and pass through model\n",
        "    probas = F.softmax(outputs.logits).cpu().detach().numpy()  # Get class probabilities using softmax\n",
        "    return probas\n",
        "\n",
        "# Initialize LimeTextExplainer to explain model predictions\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "# Lists to store the explanations for each text sample\n",
        "lista_words_general = []\n",
        "lista_values_general = []\n",
        "\n",
        "# Loop through the dataset for explanation\n",
        "for x in range(len(data)):\n",
        "    torch.cuda.empty_cache()  # Clear GPU memory to avoid running out of memory during processing\n",
        "    with torch.no_grad():  # Disable gradient computation for faster predictions\n",
        "        print(x)  # Print index to track progress\n",
        "        # Check the predicted label for the current instance\n",
        "        if data.loc[x, \"prediction_label_iniziale\"] == 2:\n",
        "            pred = \"LABEL_0\"  # Hate speech\n",
        "        else:\n",
        "            pred = \"LABEL_1\"  # Non-hate speech\n",
        "\n",
        "        lista_words_specific = []  # List to store words for the current explanation\n",
        "        lista_values_specific = []  # List to store feature importances for the current explanation\n",
        "\n",
        "        str_to_predict = data.loc[x, \"text\"]  # Get the text to predict\n",
        "        # Generate the explanation for the prediction\n",
        "        exp = explainer.explain_instance(str_to_predict, predictor, num_features=20, num_samples=100)\n",
        "\n",
        "        # Sort the features based on the predicted label\n",
        "        if pred == \"LABEL_1\":\n",
        "            sorted_lst = [x for x in exp.as_list() if x[1] < 0]  # Select features with negative impact\n",
        "            sorted_lst = sorted(sorted_lst, key=lambda x: x[1], reverse=False)  # Sort by importance (negative first)\n",
        "        else:\n",
        "            sorted_lst = [x for x in exp.as_list() if x[1] > 0]  # Select features with positive impact\n",
        "            sorted_lst = sorted(sorted_lst, key=lambda x: x[1], reverse=True)  # Sort by importance (positive first)\n",
        "\n",
        "        # Append sorted words and their values for the explanation\n",
        "        for x in sorted_lst:\n",
        "            lista_words_specific.append(x[0])  # Append the word\n",
        "            lista_values_specific.append(x[1])  # Append the importance value\n",
        "\n",
        "        # Append the words and values for this instance to the general lists\n",
        "        lista_words_general.append(lista_words_specific)\n",
        "        lista_values_general.append(lista_values_specific)\n",
        "\n",
        "# Add the explanations to the DataFrame as a new column\n",
        "data[\"lime_words\"] = lista_words_general"
      ],
      "metadata": {
        "id": "FF6bGliIpNw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the Adversarial Attack"
      ],
      "metadata": {
        "id": "cAaTRTufp2PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Function to replace a character at a specific index in a string\n",
        "def replace_str_index(text, index=0, replacement=''):\n",
        "    return f'{text[:index]}{replacement}{text[index+1:]}'\n",
        "\n",
        "# Function to find a synonym for a word from WordNet\n",
        "def bug_sub_w(word):\n",
        "    name_app = \"\"\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for name in syn.lemma_names():\n",
        "            if name != word:\n",
        "                name_app = name\n",
        "                break\n",
        "        if name_app != \"\":\n",
        "            break\n",
        "    return name_app\n",
        "\n",
        "# Function to insert a space in the middle of the word\n",
        "def bug_insert(word):\n",
        "    if len(word) < 2:\n",
        "        return word\n",
        "    else:\n",
        "        ind = len(word) // 2\n",
        "        word_bug = word[:ind] + \" \" + word[ind:]\n",
        "        return word_bug\n",
        "\n",
        "# Function to delete a character in the middle of the word\n",
        "def bug_delete(word):\n",
        "    if len(word) < 2:\n",
        "        return word\n",
        "    else:\n",
        "        ind = len(word) // 2\n",
        "        word_bug = word[:ind] + word[ind+1:]\n",
        "        return word_bug\n",
        "\n",
        "# Function to swap characters near the middle of the word\n",
        "def bug_swap(word):\n",
        "    if len(word) < 2:\n",
        "        return word\n",
        "    elif len(word) == 2:\n",
        "        word_bug = word[1] + word[0]\n",
        "        return word_bug\n",
        "    else:\n",
        "        ind = len(word) // 2\n",
        "        lett = word[ind:ind+1]\n",
        "        word_bug = word[:ind-1] + lett + word[ind-1:ind] + word[ind+1:]\n",
        "        return word_bug\n",
        "\n",
        "# Function to replace a character with a common \"leet\" character (e.g., 'a' to '@')\n",
        "def bug_sub_c(word):\n",
        "    word = word.lower()\n",
        "    if len(word) > 2:\n",
        "        x = math.ceil(len(word) / 2)\n",
        "        if word[x] in [\"a\", \"b\", \"c\", \"e\", \"g\", \"h\", \"i\", \"l\", \"o\", \"s\", \"t\", \"z\"]:\n",
        "            if word[x] == \"a\":\n",
        "                word = replace_str_index(word, x, \"@\")\n",
        "            elif word[x] == \"b\":\n",
        "                word = replace_str_index(word, x, \"8\")\n",
        "            elif word[x] == \"c\":\n",
        "                word = replace_str_index(word, x, \"(\")\n",
        "            elif word[x] == \"e\":\n",
        "                word = replace_str_index(word, x, \"3\")\n",
        "            elif word[x] == \"g\":\n",
        "                word = replace_str_index(word, x, \"6\")\n",
        "            elif word[x] == \"h\":\n",
        "                word = replace_str_index(word, x, \"#\")\n",
        "            elif word[x] == \"i\":\n",
        "                word = replace_str_index(word, x, \"!\")\n",
        "            elif word[x] == \"l\":\n",
        "                word = replace_str_index(word, x, \"1\")\n",
        "            elif word[x] == \"o\":\n",
        "                word = replace_str_index(word, x, \"0\")\n",
        "            elif word[x] == \"s\":\n",
        "                word = replace_str_index(word, x, \"$\")\n",
        "            elif word[x] == \"t\":\n",
        "                word = replace_str_index(word, x, \"7\")\n",
        "            elif word[x] == \"z\":\n",
        "                word = replace_str_index(word, x, \"2\")\n",
        "        else:\n",
        "            x = x - 1\n",
        "            if word[x] in [\"a\", \"b\", \"c\", \"e\", \"g\", \"h\", \"i\", \"l\", \"o\", \"s\", \"t\", \"z\"]:\n",
        "                if word[x] == \"a\":\n",
        "                    word = replace_str_index(word, x, \"@\")\n",
        "                elif word[x] == \"b\":\n",
        "                    word = replace_str_index(word, x, \"8\")\n",
        "                elif word[x] == \"c\":\n",
        "                    word = replace_str_index(word, x, \"(\")\n",
        "                elif word[x] == \"e\":\n",
        "                    word = replace_str_index(word, x, \"3\")\n",
        "                elif word[x] == \"g\":\n",
        "                    word = replace_str_index(word, x, \"6\")\n",
        "                elif word[x] == \"h\":\n",
        "                    word = replace_str_index(word, x, \"#\")\n",
        "                elif word[x] == \"i\":\n",
        "                    word = replace_str_index(word, x, \"!\")\n",
        "                elif word[x] == \"l\":\n",
        "                    word = replace_str_index(word, x, \"1\")\n",
        "                elif word[x] == \"o\":\n",
        "                    word = replace_str_index(word, x, \"0\")\n",
        "                elif word[x] == \"s\":\n",
        "                    word = replace_str_index(word, x, \"$\")\n",
        "                elif word[x] == \"t\":\n",
        "                    word = replace_str_index(word, x, \"7\")\n",
        "                elif word[x] == \"z\":\n",
        "                    word = replace_str_index(word, x, \"2\")\n",
        "    return word\n"
      ],
      "metadata": {
        "id": "PStsDaRbpuee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack to 1 word"
      ],
      "metadata": {
        "id": "RGjtx0iyrJiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define the list of attack functions\n",
        "funzioni = [bug_insert, bug_delete, bug_swap, bug_sub_c, bug_sub_c]\n",
        "\n",
        "# Initialize a list to store the modified sentences\n",
        "lista_frasi = []\n",
        "for x in range(len(data)):\n",
        "    print(x)\n",
        "    # Randomly select an attack function to apply\n",
        "    funzioni_selezionate = random.sample(funzioni, 1)\n",
        "\n",
        "    for funzione in funzioni_selezionate:\n",
        "        frase = data.loc[x, \"text\"]  # Get the original text\n",
        "        lime_words = data.loc[x, \"lime_words\"][:1]  # Select only the most important word (just one word)\n",
        "        word_to_attack_list = []  # List to store modified words\n",
        "\n",
        "        # Apply the attack function to the selected word\n",
        "        for j in lime_words:\n",
        "            word_to_attack_list.append(funzione(j))\n",
        "\n",
        "        # Replace the original word with the attacked word in the sentence\n",
        "        for y in range(len(word_to_attack_list)):\n",
        "            frase = frase.replace(lime_words[y], word_to_attack_list[y])\n",
        "\n",
        "    lista_frasi.append(frase)  # Add the modified sentence to the list\n",
        "\n",
        "# Update the text column in the data with the modified sentences\n",
        "data[\"text\"] = lista_frasi\n",
        "\n",
        "# Initialize a list to store the predictions after the attack\n",
        "list_result = []\n",
        "for i in range(len(data)):\n",
        "    print(i)\n",
        "    # Predict the label for each modified sentence\n",
        "    list_result.append(clf(data.loc[i, \"text\"]))\n",
        "\n",
        "# Extract the predicted labels from the results\n",
        "risultati = []\n",
        "for i in range(len(list_result)):\n",
        "    risultati.append(list_result[i][0][\"label\"])\n",
        "\n",
        "# Add the predicted labels to the data\n",
        "data[\"prediction_label_finale\"] = risultati\n",
        "\n",
        "# Replace the original label format with the numeric format for accuracy calculation\n",
        "data.prediction_label_finale.replace(\"LABEL_0\", 2, inplace=True)\n",
        "data.prediction_label_finale.replace(\"LABEL_1\", 0, inplace=True)\n",
        "\n",
        "# Convert the final predictions and actual labels to integers for accuracy calculation\n",
        "data[\"prediction_label_finale\"] = data[\"prediction_label_finale\"].astype(int)\n",
        "\n",
        "# Calculate accuracy by comparing the predicted labels with the true labels\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(data[\"hatespeech\"], data[\"prediction_label_finale\"])\n",
        "\n",
        "print(\"ACCURACY AFTER ATTACK ON 1 WORD:\", accuracy)\n",
        "\n",
        "# Filter the data to compare correct predictions before and after the attack\n",
        "data_pred = data[data[\"hatespeech\"] == 2]  # Select only the hate speech samples\n",
        "data_initial = data_pred[data_pred.prediction_label_iniziale == 2]  # Correct predictions before the attack\n",
        "data_final = data_pred[data_pred.prediction_label_finale == 2]  # Correct predictions after the attack\n",
        "\n",
        "# Print the number of correct predictions before and after the attack\n",
        "print(\"Number of correct predictions before attack\", len(data_initial))\n",
        "print(\"Number of correct predictions after attack\", len(data_final))\n",
        "\n",
        "# Calculate the Attack Success Rate (ASR), which is the percentage of correct predictions lost after the attack\n",
        "print(\"ASR: \", (((len(data_initial) - len(data_final)) / len(data_initial)) * 100))\n",
        "\n",
        "# Generate and display the confusion matrix to evaluate the model's performance\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(list(data['hatespeech']), list(data[\"prediction_label_finale\"]))\n",
        "\n",
        "# Plot the confusion matrix using seaborn for better visualization\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"Actual label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eEHbxyiYp-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack to 3 words"
      ],
      "metadata": {
        "id": "5dMprukvsb2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PROVE CON ATTACCO SU 3 PAROLE - THE STEPS ARE THE SAME OF 1 WORD ATTACK\n",
        "import random\n",
        "\n",
        "funzioni = [bug_insert, bug_delete, bug_swap, bug_sub_c, bug_sub_c]\n",
        "\n",
        "lista_frasi = []\n",
        "for x in range(len(data)):\n",
        "    print(x)\n",
        "    funzioni_selezionate = random.sample(funzioni, 3)\n",
        "\n",
        "    for funzione in funzioni_selezionate:\n",
        "        frase = data.loc[x, \"text\"]\n",
        "        lime_words = data.loc[x, \"lime_words\"][:3] # Set the word to attack at 3\n",
        "        word_to_attack_list = []\n",
        "        for j in lime_words:\n",
        "            word_to_attack_list.append(funzione(j))\n",
        "        for y in range(len(word_to_attack_list)):\n",
        "            frase = frase.replace(lime_words[y], word_to_attack_list[y])\n",
        "    lista_frasi.append(frase)\n",
        "\n",
        "data[\"text\"] = lista_frasi\n",
        "\n",
        "list_result = []\n",
        "for i in range(len(data)):\n",
        "    list_result.append(clf(data.loc[i, \"text\"]))\n",
        "\n",
        "risultati = []\n",
        "for i in range(len(list_result)):\n",
        "    risultati.append(list_result[i][0][\"label\"])\n",
        "\n",
        "data[\"prediction_label_finale\"] = risultati\n",
        "\n",
        "data.prediction_label_finale.replace(\"LABEL_0\", 2, inplace=True)\n",
        "data.prediction_label_finale.replace(\"LABEL_1\", 0, inplace=True)\n",
        "\n",
        "data[\"prediction_label_finale\"] = data[\"prediction_label_finale\"].astype(int)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(data[\"hatespeech\"], data[\"prediction_label_finale\"])\n",
        "\n",
        "print(\"ACCURACY AFTER ATTACK ON 3 WORDS:\", accuracy)\n",
        "\n",
        "data_pred = data[data[\"hatespeech\"] == 2]\n",
        "data_iniziale = data_pred[data_pred.prediction_label_iniziale == 2]\n",
        "data_finale = data_pred[data_pred.prediction_label_finale == 2]\n",
        "print(\"Numero predizioni giuste pre-attacco\", len(data_iniziale))\n",
        "print(\"Numero predizioni giuste post-attacco\", len(data_finale))\n",
        "print(\"ASR: \", (((len(data_iniziale) - len(data_finale)) / len(data_iniziale)) * 100))\n",
        "\n",
        "cm = confusion_matrix(list(data['hatespeech']), list(data[\"prediction_label_finale\"]))\n",
        "\n",
        "# Plot confusion matrix using seaborn\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"Actual label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yYh_AxKPsd-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack to 5 words"
      ],
      "metadata": {
        "id": "Ffi6OwUtvMZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PROVE CON ATTACCO SU 5 PAROLE\n",
        "import random\n",
        "\n",
        "# List of functions that perform different types of text manipulations\n",
        "funzioni = [bug_insert, bug_delete, bug_swap, bug_sub_c, bug_sub_c]\n",
        "\n",
        "# List to store modified sentences\n",
        "lista_frasi = []\n",
        "\n",
        "# Loop through each row in the dataset\n",
        "for x in range(len(data)):\n",
        "    print(x)\n",
        "\n",
        "    # Randomly select 5 functions to apply to the text\n",
        "    funzioni_selezionate = random.sample(funzioni, 5)\n",
        "\n",
        "    # Apply each of the selected functions to the text\n",
        "    for funzione in funzioni_selezionate:\n",
        "        frase = data.loc[x, \"text\"]  # Get the original sentence\n",
        "        lime_words = data.loc[x, \"lime_words\"][:5]  # Set the words to attack at 5\n",
        "        word_to_attack_list = []\n",
        "\n",
        "        # For each word in the LIME explanation, apply the attack function\n",
        "        for j in lime_words:\n",
        "            word_to_attack_list.append(funzione(j))\n",
        "\n",
        "        # Replace each word in the sentence with the manipulated version\n",
        "        for y in range(len(word_to_attack_list)):\n",
        "            frase = frase.replace(lime_words[y], word_to_attack_list[y])\n",
        "\n",
        "    lista_frasi.append(frase)  # Add the modified sentence to the list\n",
        "\n",
        "# Update the text column with the modified sentences\n",
        "data[\"text\"] = lista_frasi\n",
        "\n",
        "# List to store the prediction results for each modified sentence\n",
        "list_result = []\n",
        "for i in range(len(data)):\n",
        "    list_result.append(clf(data.loc[i, \"text\"]))  # Apply the classifier to the modified text\n",
        "\n",
        "# Extract the predicted labels from the classifier's result\n",
        "risultati = []\n",
        "for i in range(len(list_result)):\n",
        "    risultati.append(list_result[i][0][\"label\"])\n",
        "\n",
        "# Add the predicted labels to the dataframe\n",
        "data[\"prediction_label_finale\"] = risultati\n",
        "\n",
        "# Replace LABEL_0 and LABEL_1 with their respective integer labels (for comparison)\n",
        "data.prediction_label_finale.replace(\"LABEL_0\", 2, inplace=True)\n",
        "data.prediction_label_finale.replace(\"LABEL_1\", 0, inplace=True)\n",
        "\n",
        "# Convert the prediction labels to integers\n",
        "data[\"prediction_label_finale\"] = data[\"prediction_label_finale\"].astype(int)\n",
        "\n",
        "# Import the necessary metric for evaluating accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate the accuracy of the model after applying the attacks\n",
        "accuracy = accuracy_score(data[\"hatespeech\"], data[\"prediction_label_finale\"])\n",
        "print(\"ACCURACY AFTER ATTACK ON 5 WORDS:\", accuracy)\n",
        "\n",
        "# Filter the rows where the original label is 2 (target label)\n",
        "data_pred = data[data[\"hatespeech\"] == 2]\n",
        "# Get the rows where the initial prediction was also 2\n",
        "data_iniziale = data_pred[data_pred.prediction_label_iniziale == 2]\n",
        "# Get the rows where the final prediction is also 2 (after attack)\n",
        "data_finale = data_pred[data_pred.prediction_label_finale == 2]\n",
        "\n",
        "# Print the number of correct predictions before and after the attack\n",
        "print(\"Numero predizioni giuste pre-attacco\", len(data_iniziale))\n",
        "print(\"Numero predizioni giuste post-attacco\", len(data_finale))\n",
        "\n",
        "# Calculate the Attack Success Rate (ASR), which is the percentage of predictions that changed after the attack\n",
        "print(\"ASR: \", (((len(data_iniziale) - len(data_finale)) / len(data_iniziale)) * 100))\n",
        "\n",
        "# Import confusion matrix to evaluate the model's performance\n",
        "cm = confusion_matrix(list(data['hatespeech']), list(data[\"prediction_label_finale\"]))\n",
        "\n",
        "# Plot the confusion matrix using seaborn for better visualization\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"Actual label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "emSQv2XovPCp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}